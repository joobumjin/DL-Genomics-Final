{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iisFGa7NRGm_",
        "outputId": "cc533d83-fc10-413a-aeef-b345f1616947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shareddrives/DeepBio\n",
            " \u001b[0m\u001b[01;34mcheckpoints\u001b[0m/  'Full Model.ipynb'   \u001b[01;34mGM12878\u001b[0m/  'HiC Visualization'\n",
            " \u001b[01;34mE116\u001b[0m/         \u001b[01;34m'GC Merge Data'\u001b[0m/     \u001b[01;34mH1-hESC\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# %cd \"drive/MyDrive/DL for Genomics Final Project/Data Demos/GC MERGE Data\"\n",
        "%cd \"drive/Shareddrives/DeepBio\"\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import load_npz, find\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, Flatten, Dense, MaxPooling1D, Reshape, Conv2DTranspose\n",
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "BpenLzD6RUyG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/GC Merge Data/data\"\n",
        "cell_line = \"E116\"\n",
        "regression_flag = 0\n",
        "chip_res = 10000\n",
        "hic_res = 10000\n",
        "num_hm = 5\n",
        "num_feat = int((hic_res/chip_res)*num_hm)\n",
        "slice_len = 256"
      ],
      "metadata": {
        "id": "oZiuYf29RWI5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample_sparse_hic_matrix(sparse_matrix, downsample_factor):\n",
        "    # Generate random scaling factors for each read, ensuring a different factor for each\n",
        "    random_factors = tf.random.uniform(tf.shape(sparse_matrix.values), 0, downsample_factor, dtype=tf.dtypes.double)\n",
        "\n",
        "    # Apply downsampling\n",
        "    downsampled_values = sparse_matrix.values * random_factors\n",
        "    downsampled_sparse_tensor = tf.SparseTensor(indices=sparse_matrix.indices, values=downsampled_values, dense_shape=sparse_matrix.dense_shape)\n",
        "\n",
        "    # Normalize the downsampling to ensure the total reads is approximately 1/16th of the original\n",
        "    total_reads_original = tf.reduce_sum(sparse_matrix.values)\n",
        "    total_reads_downsampled = tf.reduce_sum(downsampled_sparse_tensor.values)\n",
        "    adjustment_factor = (total_reads_original / 16) / total_reads_downsampled\n",
        "    adjusted_values = downsampled_sparse_tensor.values * adjustment_factor\n",
        "    adjusted_downsampled_sparse_tensor = tf.SparseTensor(indices=sparse_matrix.indices, values=adjusted_values, dense_shape=sparse_matrix.dense_shape)\n",
        "\n",
        "    return adjusted_downsampled_sparse_tensor"
      ],
      "metadata": {
        "id": "2gRO7JGKRXO6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(tf.keras.Model):\n",
        "  def __init__(self, hic_encoder, epigenomic_encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.hic_encoder = hic_encoder\n",
        "    self.epigenomic_encoder = epigenomic_encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs, *args, **kwargs):\n",
        "    low_hic, hms = inputs\n",
        "    hic_encoded = self.hic_encoder(low_hic, *args, **kwargs)\n",
        "    hm_encoded = self.epigenomic_encoder(hms, *args, **kwargs)\n",
        "\n",
        "    concat_encodings = tf.concat((hic_encoded, hm_encoded), axis=1)\n",
        "    # print(f\"Combined Multimodal Shape: {concat_encodings.shape}\")\n",
        "    recon_hic = self.decoder(concat_encodings,*args, **kwargs)\n",
        "\n",
        "    return recon_hic\n",
        "\n",
        "hic_encoder = Sequential(\n",
        "    layers = [tf.keras.layers.InputLayer(input_shape=(slice_len, slice_len, 1)),\n",
        "              Conv2D(1, 16, (3, 3), activation='relu'),\n",
        "              MaxPooling2D((2, 2)),\n",
        "              Conv2D(16, (3, 3), activation='relu'),\n",
        "              MaxPooling2D((2, 2)),\n",
        "              Conv2D(64, (3, 3), activation='relu'),\n",
        "              MaxPooling2D((2, 2)),\n",
        "              Flatten()],\n",
        "    name=\"Convoltuional HiC Slice Encoder\")\n",
        "\n",
        "epigenomic_encoder = Sequential(\n",
        "    layers = [tf.keras.layers.InputLayer(input_shape=(slice_len,num_feat)),\n",
        "              Conv1D(16, 3, activation='relu'),\n",
        "              MaxPooling1D(2),\n",
        "              Conv1D(32, 3, activation='relu'),\n",
        "              MaxPooling1D(2),\n",
        "              Conv1D(64, 3, activation='relu'),\n",
        "              MaxPooling1D(2),\n",
        "              Conv1D(128, 3, activation='relu'),\n",
        "              MaxPooling1D(2),\n",
        "              Conv1D(128, 3, activation='relu'),\n",
        "              MaxPooling1D(2),\n",
        "              Flatten()],\n",
        "    name=\"1D Convoltuional Epgigenomic Encoder\")\n",
        "\n",
        "decoder = Sequential([tf.keras.layers.InputLayer(input_shape=(4864)),\n",
        "                      Dense(1024),\n",
        "                      Reshape(target_shape=(32, 32, 1)),\n",
        "                      Conv2DTranspose(4, (3,3), strides=2, activation=\"relu\", padding=\"same\"),\n",
        "                      Conv2DTranspose(32, (3,3), strides=2, activation=\"relu\", padding=\"same\"),\n",
        "                      Conv2DTranspose(64, (3,3), strides=2, activation=\"relu\", padding=\"same\"),\n",
        "                      Conv2D(1, (3, 3), activation='relu', padding=\"same\"),\n",
        "                      ], name=\"HiC Decoder\")\n",
        "\n",
        "autoencoder = Autoencoder(hic_encoder, epigenomic_encoder, decoder)\n",
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(), loss = tf.keras.losses.MeanSquaredError())"
      ],
      "metadata": {
        "id": "lQ7Kh3O5SU6D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "discriminator = Sequential([tf.keras.layers.InputLayer(input_shape=(slice_len, slice_len, 1)),\n",
        "                            Conv2D(16, (3, 3), activation='relu'),\n",
        "                            MaxPooling2D((2, 2)),\n",
        "                            Conv2D(32, (3, 3), activation='relu'),\n",
        "                            MaxPooling2D((2, 2)),\n",
        "                            Conv2D(32, (3, 3), activation='relu'),\n",
        "                            MaxPooling2D((2, 2)),\n",
        "                            Conv2D(64, (3, 3), activation='relu'),\n",
        "                            MaxPooling2D((2, 2)),\n",
        "                            Conv2D(128, (3, 3), activation='relu'),\n",
        "                            MaxPooling2D((2, 2)),\n",
        "                            Flatten(),\n",
        "                            Dense(512, activation='relu'),\n",
        "                            Dense(64, activation='relu'),\n",
        "                            Dense(1, activation='sigmoid')],\n",
        "                           name=\"Discriminator\")\n",
        "\n",
        "# Compile the model\n",
        "discriminator.compile(optimizer='adam', loss = tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "xvGfi1_ZSXZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92def16d-0e61-4a53-9bf5-0c75afdb55a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 254, 254, 16)      160       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 127, 127, 16)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 125, 125, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 62, 62, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 60, 60, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 30, 30, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 14, 14, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 6, 6, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               2359808   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2499105 (9.53 MB)\n",
            "Trainable params: 2499105 (9.53 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder(inputs = (tf.zeros((1, 256, 256)), tf.zeros((1, 256, 5))), training=False)\n",
        "discriminator(tf.zeros((1, 256, 256, 1)), training=False)\n",
        "\n",
        "chpt_dir = f\"./checkpoints/full_train scuff\"\n",
        "autoencoder.load_weights(f\"{chpt_dir}/autoencoder_weights.keras\")\n",
        "decoder.load_weights(f\"{chpt_dir}/decoder_weights.keras\")"
      ],
      "metadata": {
        "id": "Mkt8XGtuS4hG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chr_num = 11\n",
        "print(f\"Testing on Chromosome {chr_num}\")\n",
        "folder = f\"{base_path}/{cell_line}/{hic_res}/chr{chr_num}\"\n",
        "hic_sparse_mat_file = f\"{folder}/hic_sparse_redone_h3k27ac_addition.npz\"\n",
        "\n",
        "np_hmods_norm_all_file = f\"{folder}/np_hmods_norm_chip_{chip_res}bp_redone_h3k27ac_addition.npy\"\n",
        "\n",
        "mat = load_npz(hic_sparse_mat_file)\n",
        "\n",
        "hms = np.load(np_hmods_norm_all_file)\n",
        "hms = hms[:, 1:] #only includes features, not node ids\n",
        "hms = tf.convert_to_tensor(hms.reshape(-1, num_feat), dtype=tf.float32)"
      ],
      "metadata": {
        "id": "b8Ke8kg4SeTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887210a3-ce7f-4ae8-8193-1ef9b7817dc8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on Chromosome 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TAKEN FROM CAESAR!! https://github.com/liu-bioinfo-lab/caesar\n",
        "import os\n",
        "import numpy as np\n",
        "# from scipy.signal import convolve2d\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "\n",
        "def visualize_HiC_epigenetics(HiC, epis, output, fig_width=12.0,\n",
        "                              vmin=0, vmax=None, cmap='Reds', colorbar=True,\n",
        "                              colorbar_orientation='vertical',\n",
        "                              epi_labels=None, x_ticks=None, fontsize=24,\n",
        "                              epi_colors=None, epi_yaxis=True,\n",
        "                              heatmap_ratio=0.6, epi_ratio=0.1,\n",
        "                              interval_after_heatmap=0.05, interval_between_epi=0.01, ):\n",
        "    \"\"\"\n",
        "    Visualize matched HiC and epigenetic signals in one figure\n",
        "    Args:\n",
        "        HiC (numpy.array): Hi-C contact map, only upper triangle is used.\n",
        "        epis (list): epigenetic signals\n",
        "        output (str): the output path. Must in a proper format (e.g., 'png', 'pdf', 'svg', ...).\n",
        "        fig_width (float): the width of the figure. Then the height will be automatically calculated. Default: 12.0\n",
        "        vmin (float): min value of the colormap. Default: 0\n",
        "        vmax (float): max value of the colormap. Will use the max value in Hi-C data if not specified.\n",
        "        cmap (str or plt.cm): which colormap to use. Default: 'Reds'\n",
        "        colorbar (bool): whether to add colorbar for the heatmap. Default: True\n",
        "        colorbar_orientation (str): \"horizontal\" or \"vertical\". Default: \"vertical\"\n",
        "        epi_labels (list): the names of epigenetic marks. If None, there will be no labels at y axis.\n",
        "        x_ticks (list): a list of strings. Will be added at the bottom. THE FIRST TICK WILL BE AT THE START OF THE SIGNAL, THE LAST TICK WILL BE AT THE END.\n",
        "        fontsize (int): font size. Default: 24\n",
        "        epi_colors (list): colors of epigenetic signals\n",
        "        epi_yaxis (bool): whether add y-axis to epigenetic signals. Default: True\n",
        "        heatmap_ratio (float): the ratio of (heatmap height) and (figure width). Default: 0.6\n",
        "        epi_ratio (float): the ratio of (1D epi signal height) and (figure width). Default: 0.1\n",
        "        interval_after_heatmap (float): the ratio of (interval between heatmap and 1D signals) and (figure width). Default: 0.05\n",
        "        interval_between_epi (float): the ratio of (interval between 1D signals) and (figure width). Default: 0.01\n",
        "\n",
        "    No return. Save a figure only.\n",
        "    \"\"\"\n",
        "\n",
        "    # Make sure the lengths match\n",
        "    # len_epis = [len(epi) for epi in epis]\n",
        "    # if max(len_epis) != min(len_epis) or max(len_epis) != len(HiC):\n",
        "    #     raise ValueError('Size not matched!')\n",
        "    N = len(HiC)\n",
        "\n",
        "    # Define the space for each row (heatmap - interval - signal - interval - signal ...)\n",
        "    rs = [heatmap_ratio, interval_after_heatmap] + [epi_ratio, interval_between_epi] * len(epis)\n",
        "    rs = np.array(rs[:-1])\n",
        "\n",
        "    # Calculate figure height\n",
        "    fig_height = fig_width * np.sum(rs)\n",
        "    rs = rs / np.sum(rs)  # normalize to 1 (ratios)\n",
        "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
        "\n",
        "    # Split the figure into rows with different heights\n",
        "    gs = GridSpec(len(rs), 1, height_ratios=rs)\n",
        "\n",
        "    # Ready for plotting heatmap\n",
        "    ax0 = plt.subplot(gs[0, :])\n",
        "    # Define the rotated axes and coordinates\n",
        "    coordinate = np.array([[[(x + y) / 2, y - x] for y in range(N + 1)] for x in range(N + 1)])\n",
        "    X, Y = coordinate[:, :, 0], coordinate[:, :, 1]\n",
        "    # Plot the heatmap\n",
        "    vmax = vmax if vmax is not None else np.max(HiC)\n",
        "    im = ax0.pcolormesh(X, Y, HiC, vmin=vmin, vmax=vmax, cmap=cmap)\n",
        "    ax0.axis('off')\n",
        "    ax0.set_ylim([0, N])\n",
        "    ax0.set_xlim([0, N])\n",
        "    if colorbar:\n",
        "        if colorbar_orientation == 'horizontal':\n",
        "            _left, _width, _bottom, _height = 0.12, 0.25, 1 - rs[0] * 0.25, rs[0] * 0.03\n",
        "        elif colorbar_orientation == 'vertical':\n",
        "            _left, _width, _bottom, _height = 0.9, 0.02, 1 - rs[0] * 0.7, rs[0] * 0.5\n",
        "        else:\n",
        "            raise ValueError('Wrong orientation!')\n",
        "        cbar = plt.colorbar(im, cax=fig.add_axes([_left, _bottom, _width, _height]),\n",
        "                            orientation=colorbar_orientation)\n",
        "        cbar.ax.tick_params(labelsize=fontsize)\n",
        "        cbar.outline.set_visible(False)\n",
        "\n",
        "    # print(rs/np.sum(rs))\n",
        "    # Ready for plotting 1D signals\n",
        "    if epi_labels:\n",
        "        assert len(epis) == len(epi_labels)\n",
        "    if epi_colors:\n",
        "        assert len(epis) == len(epi_colors)\n",
        "\n",
        "    for i, epi in enumerate(epis):\n",
        "        # print(epi.shape)\n",
        "        ax1 = plt.subplot(gs[2 + 2 * i, :])\n",
        "\n",
        "        if epi_colors:\n",
        "            ax1.fill_between(np.arange(N), 0, epi, color=epi_colors[i])\n",
        "        else:\n",
        "            ax1.fill_between(np.arange(N), 0, epi)\n",
        "        ax1.spines['left'].set_visible(False)\n",
        "        ax1.spines['right'].set_visible(False)\n",
        "        ax1.spines['top'].set_visible(False)\n",
        "        ax1.spines['bottom'].set_visible(False)\n",
        "\n",
        "        if not epi_yaxis:\n",
        "            ax1.set_yticks([])\n",
        "            ax1.set_yticklabels([])\n",
        "        else:\n",
        "            ax1.spines['right'].set_visible(True)\n",
        "            ax1.tick_params(labelsize=fontsize)\n",
        "            ax1.yaxis.tick_right()\n",
        "\n",
        "        if i != len(epis) - 1:\n",
        "            ax1.set_xticks([])\n",
        "            ax1.set_xticklabels([])\n",
        "        # ax1.axis('off')\n",
        "        # ax1.xaxis.set_visible(True)\n",
        "        # plt.setp(ax1.spines.values(), visible=False)\n",
        "        # ax1.yaxis.set_visible(True)\n",
        "\n",
        "        ax1.set_xlim([-0.5, N - 0.5])\n",
        "        if epi_labels:\n",
        "            ax1.set_ylabel(epi_labels[i], fontsize=fontsize, rotation=0)\n",
        "    ax1.spines['bottom'].set_visible(True)\n",
        "    if x_ticks:\n",
        "        tick_pos = np.linspace(0, N - 1, len(x_ticks))  # 这个坐标其实是不对的 差1个bin 但是为了ticks好看只有先这样了\n",
        "        ax1.set_xticks(tick_pos)\n",
        "        ax1.set_xticklabels(x_ticks, fontsize=fontsize)\n",
        "    else:\n",
        "        ax1.set_xticks([])\n",
        "        ax1.set_xticklabels([])\n",
        "\n",
        "    plt.savefig(output)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "JDUtwW7cRg8m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_HiC_epigenetics(mat.toarray(), tf.transpose(hms), f\"./{cell_line}/ground_truth_chr{chr_num}_hic_vis.png\",\n",
        "                          colorbar=True, interval_after_heatmap=0.,\n",
        "                          interval_between_epi=0., epi_labels=[\"H3K27me3\", \"H3K36me3\", \"H3K4me1\", \"H3K4me3\", \"H3K9me3\"],\n",
        "                          epi_yaxis=True, fontsize=20, epi_ratio=0.045,\n",
        "                          x_ticks=['', '', '', '', '', ''], vmax=np.quantile(mat.toarray(), 0.98))"
      ],
      "metadata": {
        "id": "TpwtfJbFUOHz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_hic = np.zeros(shape = mat.shape)\n",
        "\n",
        "slice_len = 256\n",
        "num_bins = len(hms)\n",
        "diag_ind = 0\n",
        "\n",
        "for i in range(0, (num_bins // slice_len) + 1):\n",
        "  if (i+1) * slice_len > num_bins:\n",
        "    i = num_bins / slice_len - 1\n",
        "  hms_sub = np.expand_dims(hms[int(i*slice_len): int((i+1) * slice_len)].numpy(), axis=0)\n",
        "  for j in range(0, (num_bins // slice_len) + 1):\n",
        "    if (j+1) * slice_len > num_bins:\n",
        "      j = num_bins / slice_len - 1\n",
        "    hic_sub = np.expand_dims(mat[int(i*slice_len):int((i+1)*slice_len), int(j*slice_len):int((j+1)*slice_len)].toarray(), axis=0)\n",
        "    hi_hic = autoencoder((hic_sub, hms_sub), training=False)\n",
        "    pred_hic[int(i*slice_len):int((i+1)*slice_len), int(j*slice_len):int((j+1)*slice_len)] = np.squeeze(hi_hic.numpy())\n",
        "\n",
        "\n",
        "visualize_HiC_epigenetics(pred_hic, tf.transpose(hms), f\"./{cell_line}/pred_chr{chr_num}_hic_vis.png\",\n",
        "                          colorbar=True, interval_after_heatmap=0.,\n",
        "                          interval_between_epi=0., epi_labels=[\"H3K27me3\", \"H3K36me3\", \"H3K4me1\", \"H3K4me3\", \"H3K9me3\"],\n",
        "                          epi_yaxis=True, fontsize=20, epi_ratio=0.045,\n",
        "                          x_ticks=['', '', '', '', '', ''], vmax=np.quantile(pred_hic, 0.98))"
      ],
      "metadata": {
        "id": "P7c3a8OSRew5"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}